{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fb9c6814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ca0d86",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa1287fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general imports\n",
    "import scipy\n",
    "from scipy.signal import hilbert\n",
    "import os\n",
    "import yaml\n",
    "import re\n",
    "import mne\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yasa\n",
    "import xml.etree.ElementTree as ET\n",
    "from joblib import Parallel, delayed\n",
    "import time\n",
    "\n",
    "# import from custom script\n",
    "import basic_mne_functions as bmf\n",
    "import shared_processing_functions as spf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c1595f",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840b2029",
   "metadata": {},
   "source": [
    "#### finding .RAW files in path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33550af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_raw(subject):\n",
    "    raw_files = []\n",
    "    for file in os.listdir(os.path.join(egi_path, subject)):\n",
    "        if not file.startswith('.'):\n",
    "            if \".RAW\" in file:\n",
    "                raw_files.append(file)\n",
    "    \n",
    "    return raw_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fee043",
   "metadata": {},
   "source": [
    "#### Finding .edf files in path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50119d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_edf():\n",
    "    raw_files = []\n",
    "    for file in os.listdir(edf_path):\n",
    "        if not file.startswith('.'):\n",
    "            if \".edf\" in file:\n",
    "                raw_files.append(file)\n",
    "    \n",
    "    return raw_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e3bf326d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_annotation(anno_file, raw):\n",
    "    # load mat file with annotation\n",
    "    mat_data = scipy.io.loadmat(anno_file)\n",
    "    states = mat_data[\"states\"]\n",
    "\n",
    "    # get values from 2d array\n",
    "    descriptions = [str(int(s[0])) for s in states]  # state labels as strings\n",
    "    onsets = [float(s[2]) for s in states]           # onset in seconds\n",
    "    durations = [float(s[3]) for s in states]        # duration in seconds\n",
    "\n",
    "    # create annotations object\n",
    "    annotations = mne.Annotations(onset=onsets, duration=durations, description=descriptions)\n",
    "\n",
    "    # set annotations\n",
    "    raw.set_annotations(annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e62f0f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_to_anno(raw):\n",
    "    segments = []\n",
    "    for onset, duration in zip(raw.annotations.onset, raw.annotations.duration):\n",
    "        seg = raw.copy().crop(tmin=onset, tmax=min(onset+duration, raw.times[-1]))  # lazy if preload=False\n",
    "        segments.append(seg)\n",
    "\n",
    "    raw_cropped = mne.concatenate_raws(segments)\n",
    "    \n",
    "    return raw_cropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "62101b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_power_band(raw):\n",
    "    sf = raw.info['sfreq']\n",
    "    results = []\n",
    "    raw.get_channel_types()\n",
    "    raw_eeg = raw.copy().pick_types(eeg=True, eog=False, emg=False, misc=False)\n",
    "    raw_eeg.get_channel_types()\n",
    "\n",
    "    # Loop over annotations\n",
    "    for annot in raw_eeg.annotations:\n",
    "        stage = annot['description']\n",
    "        onset = annot['onset']\n",
    "        duration = annot['duration']\n",
    "\n",
    "        n_chunks = int(np.ceil(duration / chunk_duration))\n",
    "\n",
    "        for i in range(n_chunks):\n",
    "            tmin = onset + i * chunk_duration\n",
    "            tmax = min(onset + duration, tmin + chunk_duration)\n",
    "\n",
    "            # Crop raw to this chunk\n",
    "            raw_chunk = raw_eeg.copy().crop(tmin=tmin, tmax=min(tmax, raw_eeg.times[-1]))\n",
    "            data = raw_chunk.get_data()           # channels x samples\n",
    "            data = data.astype(float)             # convert to float for YASA\n",
    "            if data.shape[1] < 1000:\n",
    "                continue\n",
    "            print(f\"data shape: {data.shape}\")\n",
    "\n",
    "            # Compute bandpower using YASA (returns DataFrame)\n",
    "            bp_df = yasa.bandpower(data, sf=sf, bands=bands)\n",
    "\n",
    "            # Add the stage column\n",
    "            bp_df['Stage'] = stage\n",
    "\n",
    "            # Add channel names\n",
    "            bp_df['Channel'] = raw_eeg.info['ch_names']\n",
    "\n",
    "            # Append to results\n",
    "            results.append(bp_df)\n",
    "\n",
    "    # Concatenate all chunks\n",
    "    results_df = pd.concat(results, ignore_index=True)\n",
    "\n",
    "    # Optional: average per stage/channel/band\n",
    "    bp_mean = results_df.groupby(['Stage', 'Channel']).mean().reset_index()\n",
    "\n",
    "    return bp_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "15cd82cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def electrode_loc(pos_file):\n",
    "    left_channels, right_channels = [], []\n",
    "    tree = ET.parse(pos_file)\n",
    "    root = tree.getroot()\n",
    "    egi = {'egi': 'http://www.egi.com/sensorLayout_mff'}\n",
    "\n",
    "    for sensor in root.findall('.//egi:sensor', egi):\n",
    "        electrode = sensor.find('egi:number', egi)\n",
    "        x = float(sensor.find('egi:x', egi).text)\n",
    "        if x < 0:\n",
    "            right_channels.append(f\"E{electrode.text.strip()}\")\n",
    "        else:\n",
    "            left_channels.append(f\"E{electrode.text.strip()}\")\n",
    "\n",
    "    return right_channels, left_channels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a235e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_channel(target_stage, target_band):\n",
    "    ref_ch = \"\"\n",
    "    # get dataframe with only target stage electrodes\n",
    "    df_stage = bp_mean[bp_mean['Stage'] == target_stage]\n",
    "    # get electrode with highest power\n",
    "    max_row = df_stage.loc[df_stage[target_band].idxmax()]['Channel']\n",
    "\n",
    "    raw_cropped.load_data()\n",
    "    # get integer indices\n",
    "    indices = mne.pick_channels(raw_cropped.ch_names, [\"E190\", \"E94\"])\n",
    "\n",
    "    # take average of reference channels and create a new ref channel\n",
    "    reference = mne.channels.combine_channels(\n",
    "        raw_cropped, \n",
    "        groups={\"ref\": indices},\n",
    "        method=\"mean\"\n",
    "    )\n",
    "    raw_cropped.add_channels([reference], force_update_info=True)\n",
    "    print(raw_cropped.ch_names)\n",
    "    \n",
    "\n",
    "    raw_copy = raw_cropped.copy()\n",
    "    raw_copy = raw_copy.pick([max_row, \"ref\"])\n",
    "    #raw_copy = raw_cropped.copy().pick([max_row])\n",
    "    raw_copy.load_data()\n",
    "    # apply filters to channels\n",
    "    raw_copy.apply_function(lambda x: mne.filter.detrend(x, axis=0, order=1), picks='all')\n",
    "    raw_copy.filter(l_freq=0.25, h_freq=40, picks='all')\n",
    "\n",
    "    # create bipolar channel\n",
    "    mne.set_bipolar_reference(\n",
    "        raw_copy, \n",
    "        anode=max_row, \n",
    "        cathode=\"ref\", \n",
    "        ch_name=target_band, \n",
    "        copy=False\n",
    "    )\n",
    "\n",
    "    ch_data = raw_copy.get_data(target_band)\n",
    "    \n",
    "    return max_row, ch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4a18b3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emg(raw_cropped):\n",
    "    data_copy = raw_cropped.copy()\n",
    "    emg_data = data_copy.pick(['E240', 'E243'])\n",
    "    # data = raw_cropped.copy().pick(['EMG1', 'EMG2'])\n",
    "    emg_data.load_data()\n",
    "\n",
    "    emg_data._data = mne.filter.detrend(emg_data._data, axis=1, order=1)\n",
    "    #data.filter(l_freq=0.25, h_freq=40, picks=['EMG1', 'EMG2'])\n",
    "    emg_data.filter(l_freq=0.25, h_freq=40)\n",
    "    #picks = mne.pick_channels(data.ch_names, ['E240', 'E243'])\n",
    "    #picks = mne.pick_channels(data.ch_names, ['EMG1', 'EMG2'])\n",
    "    # data_c = data.get_data(picks).copy()\n",
    "    emg_data = emg_data.get_data()\n",
    "    l, r = emg_data\n",
    "    l, r = np.abs(l), np.abs(r)\n",
    "\n",
    "    # # Step 3: envelope via Hilbert\n",
    "    l = np.abs(hilbert(l))\n",
    "    r = np.abs(hilbert(r))\n",
    "\n",
    "    # Step 4: combine (average)\n",
    "    emg_combined = (l + r) / 2\n",
    "\n",
    "    return emg_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476a785d",
   "metadata": {},
   "source": [
    "## Access config parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a710342c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('extract_egi_config.yaml') as p:\n",
    "    params = yaml.safe_load(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb85ec0a",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "743c8c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wake time (s) to save before first sleep and after last sleep\n",
    "# (30 mins, so 30(s) * 60(s))\n",
    "wake_time = params['variables']['wake_time']\n",
    "# which channels to extract\n",
    "emg_channels = params['variables']['emg_channels']\n",
    "# stage names and corresponding ids\n",
    "bands_list = params['variables']['power_bands']\n",
    "bands = [tuple(band_list) for band_list in bands_list]\n",
    "chunk_duration = params['variables']['chunk_time']\n",
    "\n",
    "# path to general data\n",
    "path_to_data = params['paths']['data']\n",
    "# partial path to raw PSG files\n",
    "path_to_egi = params['paths']['egi']\n",
    "path_to_edf = params['paths']['edf']\n",
    "# partial path to raw hypnogram annotation files\n",
    "path_to_anno_n1 = params['paths']['anno_n1']\n",
    "path_to_anno_n2 = params['paths']['anno_n2']\n",
    "# partial path to the output for the .mat files\n",
    "path_to_output = params['paths']['output']\n",
    "\n",
    "# complete file paths\n",
    "egi_path = os.path.join(path_to_data, path_to_egi)\n",
    "edf_path = os.path.join(path_to_data, path_to_edf)\n",
    "anno_n1_path = os.path.join(path_to_data, path_to_anno_n1)\n",
    "anno_n2_path = os.path.join(path_to_data, path_to_anno_n2)\n",
    "output_path = os.path.join(path_to_data, path_to_output)\n",
    "\n",
    "# regex pattern to extract subject\n",
    "sub_pattern = re.compile(r\"(S\\d{2})\")\n",
    "#night_pattern = re.compile(r\"(S\\d{2}_\\d_\\d)\")\n",
    "\n",
    "channel_name = {\n",
    "    \"E214\": \"F1\", \"E41\": \"F2\",        # frontal\n",
    "    \"E183\": \"C1\", \"E59\": \"C2\",        # central\n",
    "    \"E149\": \"O1\", \"E124\": \"O2\",       # occipital\n",
    "    \"E10\": \"EOG1\", \"E54\": \"EOG2\",     # eog\n",
    "    \"E240\": \"EMG1\", \"E243\": \"EMG2\",   # emg\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00a6ea5",
   "metadata": {},
   "source": [
    "## Find all raw and annotations files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "73f372b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "anno_files = []\n",
    "\n",
    "# find all subjects\n",
    "subjects = [\n",
    "    subject for subject in os.listdir(edf_path)\n",
    "    if sub_pattern.search(subject)\n",
    "]\n",
    "# print(f\"Amount of subjects: {len(subjects)}\")\n",
    "\n",
    "# print(f\"Amount of raw files: {len(raw_files)}\")\n",
    "\n",
    "# for anno1, anno2 in zip(os.listdir(anno_n1_path), os.listdir(anno_n2_path)):\n",
    "#     if not anno1.startswith('.') and not anno2.startswith('.'):\n",
    "#         if \".mat\" in anno1 and \".mat\" in anno2:\n",
    "#             anno_files.append(anno1)\n",
    "#             anno_files.append(anno2)\n",
    "\n",
    "# print(f\"Amount of annotation files: {len(anno_files)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42293258",
   "metadata": {},
   "source": [
    "## Create mat files for each subject"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874b4b42",
   "metadata": {},
   "source": [
    "### .RAW files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "efcf2a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for subject in subjects:\n",
    "#     # get the raw files from this current subject\n",
    "#     raw_files = find_raw(subject)\n",
    "\n",
    "#     # iterate nights of subject\n",
    "#     for file in raw_files:\n",
    "#         if \"_1\" in file:\n",
    "#             subject_n = f\"{subject}_1\"\n",
    "#         else:\n",
    "#             subject_n = f\"{subject}_2\"\n",
    "\n",
    "#          # create output directory per subject\n",
    "#         output = os.path.join(output_path, subject_n)\n",
    "#         try:\n",
    "#             os.mkdir(output)\n",
    "#         except OSError as e:\n",
    "#             print(e)\n",
    "#             print(\"Directory already exists.\")\n",
    "#             continue\n",
    "        \n",
    "#         # read raw data\n",
    "#         start = time.time()\n",
    "#         raw = mne.io.read_raw_egi(\n",
    "#             os.path.join(raw_path, subject, file),\n",
    "#             preload=False,\n",
    "#             verbose='error'\n",
    "#         )\n",
    "#         end = time.time()\n",
    "#         print(f\"Reading raw took {end-start:.4f} seconds\")\n",
    "#         directory = file.split(\" \")[0]\n",
    "#         if \"_1\" in file:\n",
    "#             for file in os.listdir(anno_n1_path):\n",
    "#                 if directory in file:\n",
    "#                     anno_file = os.path.join(anno_n1_path, file)\n",
    "#             # extract and annotate raw data\n",
    "#             add_annotation(anno_file, raw)\n",
    "#         else:\n",
    "#             for file in os.listdir(anno_n2_path):\n",
    "#                 if directory in file:\n",
    "#                     anno_file = os.path.join(anno_n2_path, file)\n",
    "#             # extract and annotate raw data\n",
    "#             add_annotation(anno_file, raw)\n",
    "\n",
    "#         for file in os.listdir(os.path.join(raw_path, subject)):\n",
    "#             if not file.startswith(\".\"):\n",
    "#                 dir_path = os.path.join(raw_path, subject, file)\n",
    "#                 if os.path.isdir(dir_path) and directory in file:\n",
    "#                     pos_file = os.path.join(dir_path, \"sensorLayout.xml\")\n",
    "\n",
    "#         # create list to save sleep states to\n",
    "#         sleep_states = []\n",
    "        \n",
    "#         ### Cropping\n",
    "#         ################################################################\n",
    "#         if raw.times[-1] > raw.annotations.duration.sum():\n",
    "#             cropped_to_anno_raw = crop_to_anno(raw)\n",
    "#         #crop the raw data\n",
    "#         raw_cropped = bmf.crop_data(cropped_to_anno_raw, wake_time)\n",
    "#         ################################################################\n",
    "\n",
    "#         ### Sleep states\n",
    "#         ################################################################\n",
    "#         # get sleep states from cropped raw and save to .mat file\n",
    "#         sleep_states = spf.get_stages(raw_cropped, {\"0\":0,\"1\":1,\"2\":2,\"3\":3,\"5\":4})\n",
    "#         spf.create_mat(output, subject_n, \"sleep_states\", sleep_states)\n",
    "#         ################################################################\n",
    "\n",
    "#         # electrode locations\n",
    "#         right_channels, left_channels = electrode_loc(pos_file)\n",
    "\n",
    "#         ### PSD\n",
    "#         ################################################################\n",
    "#         start = time.time()\n",
    "#         print(len(raw_cropped))\n",
    "#         bp_mean = get_power_band(raw_cropped)\n",
    "#         end = time.time()\n",
    "#         print(f\"Computing PSD took {end-start:.4f} seconds\")\n",
    "#         ################################################################\n",
    "\n",
    "#         ### get the best channel for each power band\n",
    "#         # dictionary to save the different bands with highest \n",
    "#         # power in specific channel\n",
    "#         channel_bands = {}\n",
    "\n",
    "#         target_stages = [\"0\", \"3\", \"1\", \"2\", \"0\", \"0\"]\n",
    "#         target_bands = [\"Noise\", \"Delta\", \"Theta\", \"Sigma\", \"Beta\", \"Gamma\"]\n",
    "#         start = time.time()\n",
    "#         results = Parallel(n_jobs=6)(delayed(best_channel)(target_stage, target_band) for target_stage, target_band in zip(target_stages, target_bands))\n",
    "#         print(results)\n",
    "#         end = time.time()\n",
    "#         print(f\"Retrieving best channel took {end-start:.4f} seconds\")\n",
    "#         counter = 0\n",
    "#         for r in results:\n",
    "#             print(r)\n",
    "#             if r[0] not in channel_bands:\n",
    "#                 print(r[0])\n",
    "#                 channel_bands[r[0]] = {}\n",
    "#             channel_bands[r[0]][target_bands[counter]] = r[1] \n",
    "#             counter += 1 \n",
    "\n",
    "#         for channel, bands_d in channel_bands.items():\n",
    "#             band_list = []\n",
    "#             print(channel)\n",
    "#             print(bands_d)\n",
    "#             for band, ch_data in bands_d.items():\n",
    "#                 ch_data = ch_data\n",
    "#                 band_list.append(band)\n",
    "\n",
    "#             ch_pb = [channel] + band_list\n",
    "#             ch_pb = \"_\".join(ch_pb)\n",
    "#             spf.create_mat(output, subject_n, ch_pb, ch_data)\n",
    "\n",
    "#         emg_combined = get_emg(raw_cropped)\n",
    "#         spf.create_mat(output, subject_n, \"EMG\", emg_combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0e2c11",
   "metadata": {},
   "source": [
    "### .edf files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ea280a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WinError 183] Cannot create a file when that file already exists: 'C:\\\\Users\\\\andri\\\\school\\\\bio-informatics\\\\internship\\\\donders\\\\data\\\\human_test_data\\\\pre_processing\\\\mat_files\\\\S35_1_edf'\n",
      "Directory already exists.\n",
      "[WinError 183] Cannot create a file when that file already exists: 'C:\\\\Users\\\\andri\\\\school\\\\bio-informatics\\\\internship\\\\donders\\\\data\\\\human_test_data\\\\pre_processing\\\\mat_files\\\\S35_2_edf'\n",
      "Directory already exists.\n",
      "[WinError 183] Cannot create a file when that file already exists: 'C:\\\\Users\\\\andri\\\\school\\\\bio-informatics\\\\internship\\\\donders\\\\data\\\\human_test_data\\\\pre_processing\\\\mat_files\\\\S36_1_edf'\n",
      "Directory already exists.\n",
      "[WinError 183] Cannot create a file when that file already exists: 'C:\\\\Users\\\\andri\\\\school\\\\bio-informatics\\\\internship\\\\donders\\\\data\\\\human_test_data\\\\pre_processing\\\\mat_files\\\\S36_2_edf'\n",
      "Directory already exists.\n",
      "[WinError 183] Cannot create a file when that file already exists: 'C:\\\\Users\\\\andri\\\\school\\\\bio-informatics\\\\internship\\\\donders\\\\data\\\\human_test_data\\\\pre_processing\\\\mat_files\\\\S37_1_edf'\n",
      "Directory already exists.\n",
      "[WinError 183] Cannot create a file when that file already exists: 'C:\\\\Users\\\\andri\\\\school\\\\bio-informatics\\\\internship\\\\donders\\\\data\\\\human_test_data\\\\pre_processing\\\\mat_files\\\\S37_2_edf'\n",
      "Directory already exists.\n",
      "Extracting EDF parameters from C:\\Users\\andri\\school\\bio-informatics\\internship\\donders\\data\\human_test_data\\new_dataset\\edf\\MOTORWP4_S38_1.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading raw took 0.9911 seconds\n",
      "MOTORWP4_S38_1\n",
      "._MOTORWP4_S100_1 20220424 2.hpn\n",
      "._MOTORWP4_S100_1 20220424 2_states.mat\n",
      "._MOTORWP4_S35_1 20201211 2224.hpn\n",
      "._MOTORWP4_S35_1 20201211 2224_states.mat\n",
      "._MOTORWP4_S36_1 20210125 22.hpn\n",
      "._MOTORWP4_S36_1 20210125 22_states.mat\n",
      "._MOTORWP4_S37_1 20210226 22.hpn\n",
      "._MOTORWP4_S37_1 20210226 22_states.mat\n",
      "._MOTORWP4_S38_1 20210211 22.hpn\n",
      "C:\\Users\\andri\\school\\bio-informatics\\internship\\donders\\data\\human_test_data\\new_dataset\\HPN\\hpn_files_n1\\._MOTORWP4_S38_1 20210211 22.hpn\n",
      "._MOTORWP4_S38_1 20210211 22_states.mat\n",
      "C:\\Users\\andri\\school\\bio-informatics\\internship\\donders\\data\\human_test_data\\new_dataset\\HPN\\hpn_files_n1\\._MOTORWP4_S38_1 20210211 22_states.mat\n",
      "._MOTORWP4_S39_1 20210312 23.hpn\n",
      "._MOTORWP4_S39_1 20210312 23_states.mat\n",
      "._MOTORWP4_S40_1 20210409 .hpn\n",
      "._MOTORWP4_S40_1 20210409 _states.mat\n",
      "._MOTORWP4_S41_1 20210416 22.hpn\n",
      "._MOTORWP4_S41_1 20210416 22_states.mat\n",
      "._MOTORWP4_S42_1 20210423 22.hpn\n",
      "._MOTORWP4_S42_1 20210423 22_states.mat\n",
      "._MOTORWP4_S43_1 20210507 23.hpn\n",
      "._MOTORWP4_S43_1 20210507 23_states.mat\n",
      "._MOTORWP4_S44_1 20210617 22.hpn\n",
      "._MOTORWP4_S44_1 20210617 22_states.mat\n",
      "._MOTORWP4_S45_1.2 20210807 .hpn\n",
      "._MOTORWP4_S45_1.2 20210807 _states.mat\n",
      "._MOTORWP4_S46_1 20210827 22.hpn\n",
      "._MOTORWP4_S46_1 20210827 22_states.mat\n",
      "._MOTORWP4_S47_1 20210902 .hpn\n",
      "._MOTORWP4_S47_1 20210902 _states.mat\n",
      "._MOTORWP4_S48_1 20210819 22.hpn\n",
      "._MOTORWP4_S48_1 20210819 22_states.mat\n",
      "._MOTORWP4_S49_1 20210806 22.hpn\n",
      "._MOTORWP4_S49_1 20210806 22_states.mat\n",
      "._MOTORWP4_S50_1 20210918 22.hpn\n",
      "._MOTORWP4_S50_1 20210918 22_states.mat\n",
      "._MOTORWP4_S51_1 20210917 22.hpn\n",
      "._MOTORWP4_S51_1 20210917 22_states.mat\n",
      "._MOTORWP4_S52_1 20210901 22.hpn\n",
      "._MOTORWP4_S52_1 20210901 22_states.mat\n",
      "._MOTORWP4_S53_1 20210813 22.hpn\n",
      "._MOTORWP4_S53_1 20210813 22_states.mat\n",
      "._MOTORWP4_S54_1 20210730 23.hpn\n",
      "._MOTORWP4_S54_1 20210730 23_states.mat\n",
      "._MOTORWP4_S55_1 20210821 23.hpn\n",
      "._MOTORWP4_S55_1 20210821 23_states.mat\n",
      "._MOTORWP4_S56_1 20210812 22.hpn\n",
      "._MOTORWP4_S56_1 20210812 22_states.mat\n",
      "._MOTORWP4_S57_1 20210826 23.hpn\n",
      "._MOTORWP4_S57_1 20210826 23_states.mat\n",
      "._MOTORWP4_S58_1 20210616 23.hpn\n",
      "._MOTORWP4_S58_1 20210616 23_states.mat\n",
      "._MOTORWP4_S59_1 20210305 21.hpn\n",
      "._MOTORWP4_S59_1 20210305 21_states.mat\n",
      "._MOTORWP4_S60_1 20210430 22.hpn\n",
      "._MOTORWP4_S60_1 20210430 22_states.mat\n",
      "._MOTORWP4_S61_1 20210319 23.hpn\n",
      "._MOTORWP4_S61_1 20210319 23_states.mat\n",
      "._MOTORWP4_S62_1 20210219 22.hpn\n",
      "._MOTORWP4_S62_1 20210219 22_states.mat\n",
      "._MOTORWP4_S63_1 20210212 23.hpn\n",
      "._MOTORWP4_S63_1 20210212 23_states.mat\n",
      "._MOTORWP4_S64_1 20210729 22.hpn\n",
      "._MOTORWP4_S64_1 20210729 22_states.mat\n",
      "._MOTORWP4_S71_1 20220318 00.hpn\n",
      "._MOTORWP4_S71_1 20220318 00_states.mat\n",
      "._MOTORWP4_S72_1 20220305 23.hpn\n",
      "._MOTORWP4_S72_1 20220305 23_states.mat\n",
      "._MOTORWP4_S73_1 20220502 22.hpn\n",
      "._MOTORWP4_S73_1 20220502 22_states.mat\n",
      "._MOTORWP4_S74_1 20220404 23.hpn\n",
      "._MOTORWP4_S74_1 20220404 23_states.mat\n",
      "._MOTORWP4_S75_1 20220328 22.hpn\n",
      "._MOTORWP4_S75_1 20220328 22_states.mat\n",
      "._MOTORWP4_S76_1 20220717 22.hpn\n",
      "._MOTORWP4_S76_1 20220717 22_states.mat\n",
      "._MOTORWP4_S77_1 20220808 22.hpn\n",
      "._MOTORWP4_S77_1 20220808 22_states.mat\n",
      "._MOTORWP4_S78_1 20220629 22.hpn\n",
      "._MOTORWP4_S78_1 20220629 22_states.mat\n",
      "._MOTORWP4_S79_1 20220822 23.hpn\n",
      "._MOTORWP4_S79_1 20220822 23_states.mat\n",
      "._MOTORWP4_S80_1 20220705 22.hpn\n",
      "._MOTORWP4_S80_1 20220705 22_states.mat\n",
      "._MOTORWP4_S81_1 20220718 22.hpn\n",
      "._MOTORWP4_S81_1 20220718 22_states.mat\n",
      "._MOTORWP4_S82_1 20220814 23.hpn\n",
      "._MOTORWP4_S82_1 20220814 23_states.mat\n",
      "._MOTORWP4_S83_1 20220912 22.hpn\n",
      "._MOTORWP4_S83_1 20220912 22_states.mat\n",
      "._MOTORWP4_S84_1 20220829 23.hpn\n",
      "._MOTORWP4_S84_1 20220829 23_states.mat\n",
      "._MOTORWP4_S85_1 20220725 22.hpn\n",
      "._MOTORWP4_S85_1 20220725 22_states.mat\n",
      "._MOTORWP4_S86_1 20220906 22.hpn\n",
      "._MOTORWP4_S86_1 20220906 22_states.mat\n",
      "._MOTORWP4_S87_1 20220905 23.hpn\n",
      "._MOTORWP4_S87_1 20220905 23_states.mat\n",
      "._MOTORWP4_S88_1 20220802 .hpn\n",
      "._MOTORWP4_S88_1 20220802 _states.mat\n",
      "._MOTORWP4_S89_1 20220815 .hpn\n",
      "._MOTORWP4_S89_1 20220815 _states.mat\n",
      "._MOTORWP4_S90_1 20220628 .hpn\n",
      "._MOTORWP4_S90_1 20220628 _states.mat\n",
      "._MOTORWP4_S91_1 20220801 22.hpn\n",
      "._MOTORWP4_S91_1 20220801 22_states.mat\n",
      "._MOTORWP4_S92_1 20220623 22.hpn\n",
      "._MOTORWP4_S92_1 20220623 22_states.mat\n",
      "._MOTORWP4_S93_1 20220828 22.hpn\n",
      "._MOTORWP4_S93_1 20220828 22_states.mat\n",
      "._MOTORWP4_S94_1 20220616 23.hpn\n",
      "._MOTORWP4_S94_1 20220616 23_states.mat\n",
      "._MOTORWP4_S95_1 20220510 22.hpn\n",
      "._MOTORWP4_S95_1 20220510 22_states.mat\n",
      "._MOTORWP4_S96_1 20220228 23.hpn\n",
      "._MOTORWP4_S96_1 20220228 23_states.mat\n",
      "._MOTORWP4_S97_1 20220221 22.hpn\n",
      "._MOTORWP4_S97_1 20220221 22_states.mat\n",
      "._MOTORWP4_S98_1 20220207 23.hpn\n",
      "._MOTORWP4_S98_1 20220207 23_states.mat\n",
      "._MOTORWP4_S99_1 20220131 23.hpn\n",
      "._MOTORWP4_S99_1 20220131 23_states.mat\n",
      "MOTORWP4_S100_1 20220424 2.hpn\n",
      "MOTORWP4_S100_1 20220424 2_states.mat\n",
      "MOTORWP4_S35_1 20201211 2224.hpn\n",
      "MOTORWP4_S35_1 20201211 2224_states.mat\n",
      "MOTORWP4_S36_1 20210125 22.hpn\n",
      "MOTORWP4_S36_1 20210125 22_states.mat\n",
      "MOTORWP4_S37_1 20210226 22.hpn\n",
      "MOTORWP4_S37_1 20210226 22_states.mat\n",
      "MOTORWP4_S38_1 20210211 22.hpn\n",
      "C:\\Users\\andri\\school\\bio-informatics\\internship\\donders\\data\\human_test_data\\new_dataset\\HPN\\hpn_files_n1\\MOTORWP4_S38_1 20210211 22.hpn\n",
      "MOTORWP4_S38_1 20210211 22_states.mat\n",
      "C:\\Users\\andri\\school\\bio-informatics\\internship\\donders\\data\\human_test_data\\new_dataset\\HPN\\hpn_files_n1\\MOTORWP4_S38_1 20210211 22_states.mat\n",
      "MOTORWP4_S39_1 20210312 23.hpn\n",
      "MOTORWP4_S39_1 20210312 23_states.mat\n",
      "MOTORWP4_S40_1 20210409 .hpn\n",
      "MOTORWP4_S40_1 20210409 _states.mat\n",
      "MOTORWP4_S41_1 20210416 22.hpn\n",
      "MOTORWP4_S41_1 20210416 22_states.mat\n",
      "MOTORWP4_S42_1 20210423 22.hpn\n",
      "MOTORWP4_S42_1 20210423 22_states.mat\n",
      "MOTORWP4_S43_1 20210507 23.hpn\n",
      "MOTORWP4_S43_1 20210507 23_states.mat\n",
      "MOTORWP4_S44_1 20210617 22.hpn\n",
      "MOTORWP4_S44_1 20210617 22_states.mat\n",
      "MOTORWP4_S45_1.2 20210807 .hpn\n",
      "MOTORWP4_S45_1.2 20210807 _states.mat\n",
      "MOTORWP4_S46_1 20210827 22.hpn\n",
      "MOTORWP4_S46_1 20210827 22_states.mat\n",
      "MOTORWP4_S47_1 20210902 .hpn\n",
      "MOTORWP4_S47_1 20210902 _states.mat\n",
      "MOTORWP4_S48_1 20210819 22.hpn\n",
      "MOTORWP4_S48_1 20210819 22_states.mat\n",
      "MOTORWP4_S49_1 20210806 22.hpn\n",
      "MOTORWP4_S49_1 20210806 22_states.mat\n",
      "MOTORWP4_S50_1 20210918 22.hpn\n",
      "MOTORWP4_S50_1 20210918 22_states.mat\n",
      "MOTORWP4_S51_1 20210917 22.hpn\n",
      "MOTORWP4_S51_1 20210917 22_states.mat\n",
      "MOTORWP4_S52_1 20210901 22.hpn\n",
      "MOTORWP4_S52_1 20210901 22_states.mat\n",
      "MOTORWP4_S53_1 20210813 22.hpn\n",
      "MOTORWP4_S53_1 20210813 22_states.mat\n",
      "MOTORWP4_S54_1 20210730 23.hpn\n",
      "MOTORWP4_S54_1 20210730 23_states.mat\n",
      "MOTORWP4_S55_1 20210821 23.hpn\n",
      "MOTORWP4_S55_1 20210821 23_states.mat\n",
      "MOTORWP4_S56_1 20210812 22.hpn\n",
      "MOTORWP4_S56_1 20210812 22_states.mat\n",
      "MOTORWP4_S57_1 20210826 23.hpn\n",
      "MOTORWP4_S57_1 20210826 23_states.mat\n",
      "MOTORWP4_S58_1 20210616 23.hpn\n",
      "MOTORWP4_S58_1 20210616 23_states.mat\n",
      "MOTORWP4_S59_1 20210305 21.hpn\n",
      "MOTORWP4_S59_1 20210305 21_states.mat\n",
      "MOTORWP4_S60_1 20210430 22.hpn\n",
      "MOTORWP4_S60_1 20210430 22_states.mat\n",
      "MOTORWP4_S61_1 20210319 23.hpn\n",
      "MOTORWP4_S61_1 20210319 23_states.mat\n",
      "MOTORWP4_S62_1 20210219 22.hpn\n",
      "MOTORWP4_S62_1 20210219 22_states.mat\n",
      "MOTORWP4_S63_1 20210212 23.hpn\n",
      "MOTORWP4_S63_1 20210212 23_states.mat\n",
      "MOTORWP4_S64_1 20210729 22.hpn\n",
      "MOTORWP4_S64_1 20210729 22_states.mat\n",
      "MOTORWP4_S71_1 20220318 00.hpn\n",
      "MOTORWP4_S71_1 20220318 00_states.mat\n",
      "MOTORWP4_S72_1 20220305 23.hpn\n",
      "MOTORWP4_S72_1 20220305 23_states.mat\n",
      "MOTORWP4_S73_1 20220502 22.hpn\n",
      "MOTORWP4_S73_1 20220502 22_states.mat\n",
      "MOTORWP4_S74_1 20220404 23.hpn\n",
      "MOTORWP4_S74_1 20220404 23_states.mat\n",
      "MOTORWP4_S75_1 20220328 22.hpn\n",
      "MOTORWP4_S75_1 20220328 22_states.mat\n",
      "MOTORWP4_S76_1 20220717 22.hpn\n",
      "MOTORWP4_S76_1 20220717 22_states.mat\n",
      "MOTORWP4_S77_1 20220808 22.hpn\n",
      "MOTORWP4_S77_1 20220808 22_states.mat\n",
      "MOTORWP4_S78_1 20220629 22.hpn\n",
      "MOTORWP4_S78_1 20220629 22_states.mat\n",
      "MOTORWP4_S79_1 20220822 23.hpn\n",
      "MOTORWP4_S79_1 20220822 23_states.mat\n",
      "MOTORWP4_S80_1 20220705 22.hpn\n",
      "MOTORWP4_S80_1 20220705 22_states.mat\n",
      "MOTORWP4_S81_1 20220718 22.hpn\n",
      "MOTORWP4_S81_1 20220718 22_states.mat\n",
      "MOTORWP4_S82_1 20220814 23.hpn\n",
      "MOTORWP4_S82_1 20220814 23_states.mat\n",
      "MOTORWP4_S83_1 20220912 22.hpn\n",
      "MOTORWP4_S83_1 20220912 22_states.mat\n",
      "MOTORWP4_S84_1 20220829 23.hpn\n",
      "MOTORWP4_S84_1 20220829 23_states.mat\n",
      "MOTORWP4_S85_1 20220725 22.hpn\n",
      "MOTORWP4_S85_1 20220725 22_states.mat\n",
      "MOTORWP4_S86_1 20220906 22.hpn\n",
      "MOTORWP4_S86_1 20220906 22_states.mat\n",
      "MOTORWP4_S87_1 20220905 23.hpn\n",
      "MOTORWP4_S87_1 20220905 23_states.mat\n",
      "MOTORWP4_S88_1 20220802 .hpn\n",
      "MOTORWP4_S88_1 20220802 _states.mat\n",
      "MOTORWP4_S89_1 20220815 .hpn\n",
      "MOTORWP4_S89_1 20220815 _states.mat\n",
      "MOTORWP4_S90_1 20220628 .hpn\n",
      "MOTORWP4_S90_1 20220628 _states.mat\n",
      "MOTORWP4_S91_1 20220801 22.hpn\n",
      "MOTORWP4_S91_1 20220801 22_states.mat\n",
      "MOTORWP4_S92_1 20220623 22.hpn\n",
      "MOTORWP4_S92_1 20220623 22_states.mat\n",
      "MOTORWP4_S93_1 20220828 22.hpn\n",
      "MOTORWP4_S93_1 20220828 22_states.mat\n",
      "MOTORWP4_S94_1 20220616 23.hpn\n",
      "MOTORWP4_S94_1 20220616 23_states.mat\n",
      "MOTORWP4_S95_1 20220510 22.hpn\n",
      "MOTORWP4_S95_1 20220510 22_states.mat\n",
      "MOTORWP4_S96_1 20220228 23.hpn\n",
      "MOTORWP4_S96_1 20220228 23_states.mat\n",
      "MOTORWP4_S97_1 20220221 22.hpn\n",
      "MOTORWP4_S97_1 20220221 22_states.mat\n",
      "MOTORWP4_S98_1 20220207 23.hpn\n",
      "MOTORWP4_S98_1 20220207 23_states.mat\n",
      "MOTORWP4_S99_1 20220131 23.hpn\n",
      "MOTORWP4_S99_1 20220131 23_states.mat\n",
      "First sleep starts at: 0.0\n",
      "Last sleep ends at: 36210.52\n",
      "Cropping raw: 0 - 36210.52\n",
      "Cropping finished.\n",
      "Sleep stages variable can't be reshaped.\n",
      "Saving the sleep stages to .mat file.\n",
      "9052631\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "data shape: (12, 75001)\n",
      "data shape: (12, 75001)\n",
      "data shape: (12, 75001)\n",
      "data shape: (12, 75001)\n",
      "data shape: (12, 75001)\n",
      "data shape: (12, 52501)\n",
      "data shape: (12, 37501)\n",
      "data shape: (12, 30001)\n",
      "data shape: (12, 37501)\n",
      "data shape: (12, 75001)\n",
      "data shape: (12, 7501)\n",
      "data shape: (12, 7501)\n",
      "data shape: (12, 7501)\n",
      "data shape: (12, 75001)\n",
      "data shape: (12, 15001)\n",
      "data shape: (12, 75001)\n",
      "data shape: (12, 75001)\n",
      "data shape: (12, 75001)\n",
      "data shape: (12, 75001)\n",
      "data shape: (12, 75001)\n",
      "data shape: (12, 37501)\n",
      "data shape: (12, 7501)\n",
      "data shape: (12, 75001)\n",
      "data shape: (12, 75001)\n",
      "data shape: (12, 75001)\n",
      "data shape: (12, 37501)\n",
      "data shape: (12, 52501)\n",
      "data shape: (12, 15001)\n",
      "data shape: (12, 7501)\n",
      "data shape: (12, 7501)\n",
      "data shape: (12, 15001)\n",
      "data shape: (12, 7501)\n",
      "data shape: (12, 67501)\n",
      "data shape: (12, 7501)\n",
      "data shape: (12, 75001)\n",
      "data shape: (12, 75001)\n",
      "data shape: (12, 52501)\n",
      "data shape: (12, 30001)\n",
      "data shape: (12, 75001)\n",
      "data shape: (12, 52501)\n",
      "data shape: (12, 7501)\n",
      "data shape: (12, 7501)\n",
      "data shape: (12, 75001)\n",
      "data shape: (12, 15001)\n",
      "data shape: (12, 75001)\n",
      "data shape: (12, 75001)\n",
      "data shape: (12, 60001)\n",
      "data shape: (12, 60001)\n",
      "data shape: (12, 7501)\n",
      "data shape: (12, 7501)\n",
      "data shape: (12, 75001)\n",
      "data shape: (12, 75001)\n",
      "data shape: (12, 37501)\n",
      "data shape: (12, 15001)\n",
      "data shape: (12, 75001)\n",
      "data shape: (12, 67501)\n",
      "data shape: (12, 30001)\n",
      "data shape: (12, 37501)\n",
      "data shape: (12, 75001)\n",
      "data shape: (12, 75001)\n",
      "data shape: (12, 75001)\n",
      "data shape: (12, 75001)\n",
      "data shape: (12, 75001)\n",
      "data shape: (12, 22501)\n",
      "data shape: (12, 15001)\n",
      "data shape: (12, 75001)\n",
      "data shape: (12, 67501)\n",
      "data shape: (12, 75001)\n",
      "data shape: (12, 45001)\n",
      "data shape: (12, 7501)\n",
      "data shape: (12, 7501)\n",
      "data shape: (12, 75001)\n",
      "data shape: (12, 67501)\n",
      "data shape: (12, 7501)\n",
      "data shape: (12, 75001)\n",
      "data shape: (12, 75001)\n",
      "data shape: (12, 30001)\n",
      "data shape: (12, 7501)\n",
      "data shape: (12, 67501)\n",
      "data shape: (12, 15001)\n",
      "data shape: (12, 45001)\n",
      "data shape: (12, 7501)\n",
      "data shape: (12, 7501)\n",
      "data shape: (12, 75001)\n",
      "data shape: (12, 7501)\n",
      "data shape: (12, 7501)\n",
      "data shape: (12, 22501)\n",
      "data shape: (12, 60001)\n",
      "data shape: (12, 7501)\n",
      "data shape: (12, 52501)\n",
      "data shape: (12, 15001)\n",
      "data shape: (12, 15001)\n",
      "data shape: (12, 75001)\n",
      "data shape: (12, 75001)\n",
      "data shape: (12, 75001)\n",
      "data shape: (12, 75001)\n",
      "data shape: (12, 45001)\n",
      "data shape: (12, 30001)\n",
      "data shape: (12, 60001)\n",
      "data shape: (12, 7501)\n",
      "data shape: (12, 7501)\n",
      "data shape: (12, 30001)\n",
      "data shape: (12, 15001)\n",
      "data shape: (12, 7501)\n",
      "data shape: (12, 75001)\n",
      "data shape: (12, 60001)\n",
      "data shape: (12, 7501)\n",
      "data shape: (12, 22501)\n",
      "data shape: (12, 7501)\n",
      "data shape: (12, 7501)\n",
      "data shape: (12, 75001)\n",
      "data shape: (12, 75001)\n",
      "data shape: (12, 75001)\n",
      "data shape: (12, 75001)\n",
      "data shape: (12, 75001)\n",
      "data shape: (12, 30001)\n",
      "data shape: (12, 75001)\n",
      "data shape: (12, 60001)\n",
      "data shape: (12, 15001)\n",
      "data shape: (12, 75001)\n",
      "data shape: (12, 37501)\n",
      "data shape: (12, 22501)\n",
      "data shape: (12, 75001)\n",
      "data shape: (12, 75001)\n",
      "data shape: (12, 67501)\n",
      "data shape: (12, 22501)\n",
      "data shape: (12, 75001)\n",
      "data shape: (12, 45001)\n",
      "data shape: (12, 7501)\n",
      "data shape: (12, 7501)\n",
      "data shape: (12, 75001)\n",
      "data shape: (12, 75001)\n",
      "data shape: (12, 75001)\n",
      "data shape: (12, 75001)\n",
      "data shape: (12, 75001)\n",
      "data shape: (12, 75001)\n",
      "data shape: (12, 75001)\n",
      "data shape: (12, 22501)\n",
      "data shape: (12, 30001)\n",
      "data shape: (12, 7501)\n",
      "data shape: (12, 75001)\n",
      "data shape: (12, 30001)\n",
      "data shape: (12, 7501)\n",
      "data shape: (12, 30001)\n",
      "data shape: (12, 37501)\n",
      "data shape: (12, 22501)\n",
      "data shape: (12, 52501)\n",
      "data shape: (12, 15001)\n",
      "data shape: (12, 75001)\n",
      "data shape: (12, 75001)\n",
      "data shape: (12, 45001)\n",
      "data shape: (12, 7501)\n",
      "data shape: (12, 7501)\n",
      "data shape: (12, 75001)\n",
      "data shape: (12, 37501)\n",
      "data shape: (12, 15001)\n",
      "data shape: (12, 7501)\n",
      "data shape: (12, 52501)\n",
      "data shape: (12, 7501)\n",
      "data shape: (12, 7501)\n",
      "data shape: (12, 22501)\n",
      "data shape: (12, 75001)\n",
      "data shape: (12, 75001)\n",
      "data shape: (12, 15001)\n",
      "data shape: (12, 7501)\n",
      "data shape: (12, 15001)\n",
      "data shape: (12, 75001)\n",
      "data shape: (12, 52501)\n",
      "data shape: (12, 15001)\n",
      "data shape: (12, 52501)\n",
      "data shape: (12, 7501)\n",
      "data shape: (12, 60001)\n",
      "data shape: (12, 7501)\n",
      "data shape: (12, 7501)\n",
      "data shape: (12, 75001)\n",
      "data shape: (12, 75001)\n",
      "data shape: (12, 75001)\n",
      "data shape: (12, 7501)\n",
      "data shape: (12, 15001)\n",
      "data shape: (12, 75001)\n",
      "data shape: (12, 22501)\n",
      "data shape: (12, 7501)\n",
      "data shape: (12, 37501)\n",
      "data shape: (12, 7501)\n",
      "data shape: (12, 75001)\n",
      "data shape: (12, 75001)\n",
      "data shape: (12, 30001)\n",
      "data shape: (12, 75001)\n",
      "data shape: (12, 15001)\n",
      "data shape: (12, 7501)\n",
      "data shape: (12, 45001)\n",
      "data shape: (12, 37501)\n",
      "data shape: (12, 75001)\n",
      "data shape: (12, 75001)\n",
      "data shape: (12, 75001)\n",
      "data shape: (12, 75001)\n",
      "data shape: (12, 75001)\n",
      "data shape: (12, 52501)\n",
      "data shape: (12, 7501)\n",
      "data shape: (12, 15001)\n",
      "data shape: (12, 30001)\n",
      "data shape: (12, 7501)\n",
      "data shape: (12, 15001)\n",
      "data shape: (12, 67501)\n",
      "data shape: (12, 45001)\n",
      "Computing PSD took 38.0260 seconds\n",
      "Reading 0 ... 9052630  =      0.000 ... 36210.520 secs...\n",
      "Creating RawArray with float64 data, n_channels=1, n_times=9052631\n",
      "    Range : 0 ... 9052630 =      0.000 ... 36210.520 secs\n",
      "Ready.\n",
      "Filtering raw data in 131 contiguous segments\n",
      "Setting up band-pass filter from 0.25 - 40 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.25\n",
      "- Lower transition bandwidth: 0.25 Hz (-6 dB cutoff frequency: 0.12 Hz)\n",
      "- Upper passband edge: 40.00 Hz\n",
      "- Upper transition bandwidth: 10.00 Hz (-6 dB cutoff frequency: 45.00 Hz)\n",
      "- Filter length: 3301 samples (13.204 s)\n",
      "\n",
      "EEG channel type selected for re-referencing\n",
      "Creating RawArray with float64 data, n_channels=1, n_times=9052631\n",
      "    Range : 0 ... 9052630 =      0.000 ... 36210.520 secs\n",
      "Ready.\n",
      "Added the following bipolar channels:\n",
      "Noise\n",
      "Creating RawArray with float64 data, n_channels=1, n_times=9052631\n",
      "    Range : 0 ... 9052630 =      0.000 ... 36210.520 secs\n",
      "Ready.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The following channels are present in more than one input measurement info objects: ['ref']",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 80\u001b[39m\n\u001b[32m     78\u001b[39m target_bands = [\u001b[33m\"\u001b[39m\u001b[33mNoise\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mDelta\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mTheta\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mSigma\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mBeta\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mGamma\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     79\u001b[39m start = time.time()\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m results = \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbest_channel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_stage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_band\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtarget_stage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_band\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtarget_stages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_bands\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     81\u001b[39m \u001b[38;5;28mprint\u001b[39m(results)\n\u001b[32m     82\u001b[39m end = time.time()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\andri\\miniconda3\\envs\\rodent_model\\Lib\\site-packages\\joblib\\parallel.py:1986\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1984\u001b[39m     output = \u001b[38;5;28mself\u001b[39m._get_sequential_output(iterable)\n\u001b[32m   1985\u001b[39m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m1986\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1988\u001b[39m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[32m   1989\u001b[39m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[32m   1990\u001b[39m \u001b[38;5;66;03m# reused, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[32m   1991\u001b[39m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[32m   1992\u001b[39m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[32m   1993\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\andri\\miniconda3\\envs\\rodent_model\\Lib\\site-packages\\joblib\\parallel.py:1914\u001b[39m, in \u001b[36mParallel._get_sequential_output\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1912\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_batches += \u001b[32m1\u001b[39m\n\u001b[32m   1913\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_tasks += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1914\u001b[39m res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1915\u001b[39m \u001b[38;5;28mself\u001b[39m.n_completed_tasks += \u001b[32m1\u001b[39m\n\u001b[32m   1916\u001b[39m \u001b[38;5;28mself\u001b[39m.print_progress()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 18\u001b[39m, in \u001b[36mbest_channel\u001b[39m\u001b[34m(target_stage, target_band)\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# take average of reference channels and create a new ref channel\u001b[39;00m\n\u001b[32m     13\u001b[39m reference = mne.channels.combine_channels(\n\u001b[32m     14\u001b[39m     raw_cropped, \n\u001b[32m     15\u001b[39m     groups={\u001b[33m\"\u001b[39m\u001b[33mref\u001b[39m\u001b[33m\"\u001b[39m: indices},\n\u001b[32m     16\u001b[39m     method=\u001b[33m\"\u001b[39m\u001b[33mmean\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     17\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[43mraw_cropped\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd_channels\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mreference\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_update_info\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m raw_copy = raw_cropped.copy().pick([max_row, \u001b[33m\"\u001b[39m\u001b[33mref\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m#raw_copy = raw_cropped.copy().pick([max_row])\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\andri\\miniconda3\\envs\\rodent_model\\Lib\\site-packages\\mne\\channels\\channels.py:743\u001b[39m, in \u001b[36mUpdateChannelsMixin.add_channels\u001b[39m\u001b[34m(self, add_list, force_update_info)\u001b[39m\n\u001b[32m    741\u001b[39m \u001b[38;5;66;03m# Create final data / info objects\u001b[39;00m\n\u001b[32m    742\u001b[39m infos = [\u001b[38;5;28mself\u001b[39m.info] + [inst.info \u001b[38;5;28;01mfor\u001b[39;00m inst \u001b[38;5;129;01min\u001b[39;00m add_list]\n\u001b[32m--> \u001b[39m\u001b[32m743\u001b[39m new_info = \u001b[43m_merge_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43minfos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_update_to_first\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_update_info\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    745\u001b[39m \u001b[38;5;66;03m# Now update the attributes\u001b[39;00m\n\u001b[32m    746\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    747\u001b[39m     \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m._data, np.memmap)\n\u001b[32m    748\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m con_axis == \u001b[32m0\u001b[39m\n\u001b[32m    749\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m sys.platform != \u001b[33m\"\u001b[39m\u001b[33mdarwin\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    750\u001b[39m ):  \u001b[38;5;66;03m# resizing not available--no mremap\u001b[39;00m\n\u001b[32m    751\u001b[39m     \u001b[38;5;66;03m# Use a resize and fill in other ones\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<decorator-gen-50>:12\u001b[39m, in \u001b[36m_merge_info\u001b[39m\u001b[34m(infos, force_update_to_first, verbose)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\andri\\miniconda3\\envs\\rodent_model\\Lib\\site-packages\\mne\\_fiff\\meas_info.py:3098\u001b[39m, in \u001b[36m_merge_info\u001b[39m\u001b[34m(infos, force_update_to_first, verbose)\u001b[39m\n\u001b[32m   3093\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(duplicates) > \u001b[32m0\u001b[39m:\n\u001b[32m   3094\u001b[39m     msg = (\n\u001b[32m   3095\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe following channels are present in more than one input \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   3096\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mmeasurement info objects: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(duplicates)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   3097\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m3098\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m   3100\u001b[39m transforms = [\u001b[33m\"\u001b[39m\u001b[33mctf_head_t\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mdev_head_t\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mdev_ctf_t\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   3101\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m trans_name \u001b[38;5;129;01min\u001b[39;00m transforms:\n",
      "\u001b[31mValueError\u001b[39m: The following channels are present in more than one input measurement info objects: ['ref']"
     ]
    }
   ],
   "source": [
    "for subject in subjects:\n",
    "    subject = subject.split(\".\")[0].split(\"_\", 1)[1]\n",
    "    # get the raw files from this current subject\n",
    "    raw_files = find_edf()\n",
    "\n",
    "    # iterate nights of subject\n",
    "    for file in raw_files:\n",
    "        if subject in file:\n",
    "            subject_n = f\"{subject}_edf\"\n",
    "\n",
    "            # create output directory per subject\n",
    "            output = os.path.join(output_path, subject_n)\n",
    "            try:\n",
    "                os.mkdir(output)\n",
    "            except OSError as e:\n",
    "                print(e)\n",
    "                print(\"Directory already exists.\")\n",
    "                continue\n",
    "            \n",
    "            # read raw data\n",
    "            start = time.time()\n",
    "            raw = mne.io.read_raw_edf(os.path.join(edf_path, file))\n",
    "            end = time.time()\n",
    "            print(f\"Reading raw took {end-start:.4f} seconds\")\n",
    "            directory = file.split(\".\")[0]\n",
    "            print(directory)\n",
    "            if \"_1\" in file:\n",
    "                for file in os.listdir(anno_n1_path):\n",
    "                    print(file)\n",
    "                    if directory in file:\n",
    "                        anno_file1 = os.path.join(anno_n1_path, file)\n",
    "                        print(anno_file1)\n",
    "                # extract and annotate raw data\n",
    "                add_annotation(anno_file1, raw)\n",
    "            else:\n",
    "                for file in os.listdir(anno_n2_path):\n",
    "                    if directory in file:\n",
    "                        anno_file2 = os.path.join(anno_n2_path, file)\n",
    "                # extract and annotate raw data\n",
    "                add_annotation(anno_file2, raw)\n",
    "\n",
    "            # create list to save sleep states to\n",
    "            sleep_states = []\n",
    "            \n",
    "            ### Cropping\n",
    "            ################################################################\n",
    "            if raw.times[-1] > raw.annotations.duration.sum():\n",
    "                cropped_to_anno_raw = crop_to_anno(raw)\n",
    "            #crop the raw data\n",
    "            raw_cropped = bmf.crop_data(cropped_to_anno_raw, wake_time)\n",
    "            ################################################################\n",
    "\n",
    "            ### Sleep states\n",
    "            ################################################################\n",
    "            # get sleep states from cropped raw and save to .mat file\n",
    "            sleep_states = spf.get_stages(raw_cropped, {\"0\":0,\"1\":1,\"2\":2,\"3\":3,\"5\":4})\n",
    "            spf.create_mat(output, subject_n, \"sleep_states\", sleep_states)\n",
    "            ################################################################\n",
    "\n",
    "            # # electrode locations\n",
    "            # right_channels, left_channels = electrode_loc(pos_file)\n",
    "\n",
    "            ### PSD\n",
    "            ################################################################\n",
    "            start = time.time()\n",
    "            print(len(raw_cropped))\n",
    "            bp_mean = get_power_band(raw_cropped)\n",
    "            end = time.time()\n",
    "            print(f\"Computing PSD took {end-start:.4f} seconds\")\n",
    "            ################################################################\n",
    "\n",
    "            ### get the best channel for each power band\n",
    "            # dictionary to save the different bands with highest \n",
    "            # power in specific channel\n",
    "            channel_bands = {}\n",
    "\n",
    "            target_stages = [\"0\", \"3\", \"1\", \"2\", \"0\", \"0\"]\n",
    "            target_bands = [\"Noise\", \"Delta\", \"Theta\", \"Sigma\", \"Beta\", \"Gamma\"]\n",
    "            start = time.time()\n",
    "            results = Parallel(n_jobs=1)(delayed(best_channel)(target_stage, target_band) for target_stage, target_band in zip(target_stages, target_bands))\n",
    "            print(results)\n",
    "            end = time.time()\n",
    "            print(f\"Retrieving best channel took {end-start:.4f} seconds\")\n",
    "            counter = 0\n",
    "            for r in results:\n",
    "                print(r)\n",
    "                if r[0] not in channel_bands:\n",
    "                    print(r[0])\n",
    "                    channel_bands[r[0]] = {}\n",
    "                channel_bands[r[0]][target_bands[counter]] = r[1] \n",
    "                counter += 1 \n",
    "\n",
    "            for channel, bands_d in channel_bands.items():\n",
    "                band_list = []\n",
    "                print(channel)\n",
    "                print(bands_d)\n",
    "                for band, ch_data in bands_d.items():\n",
    "                    ch_data = ch_data\n",
    "                    print(len(ch_data))\n",
    "                    band_list.append(band)\n",
    "\n",
    "                ch_pb = [channel] + band_list\n",
    "                ch_pb = \"_\".join(ch_pb)\n",
    "                spf.create_mat(output, subject_n, ch_pb, ch_data)\n",
    "\n",
    "            emg_combined = get_emg(raw_cropped)\n",
    "            spf.create_mat(output, subject_n, \"EMG\", emg_combined)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rodent_model",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "fb9c6814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ca0d86",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "aa1287fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general imports\n",
    "import scipy\n",
    "from scipy.signal import hilbert\n",
    "import os\n",
    "import yaml\n",
    "import re\n",
    "import mne\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yasa\n",
    "import xml.etree.ElementTree as ET\n",
    "from joblib import Parallel, delayed\n",
    "import time\n",
    "\n",
    "# import from custom script\n",
    "import basic_mne_functions as bmf\n",
    "import shared_processing_functions as spf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c1595f",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840b2029",
   "metadata": {},
   "source": [
    "#### finding .RAW files in path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "33550af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_raw(subject):\n",
    "    raw_files = []\n",
    "    for file in os.listdir(os.path.join(egi_path, subject)):\n",
    "        if not file.startswith('.'):\n",
    "            if \".RAW\" in file:\n",
    "                raw_files.append(file)\n",
    "    \n",
    "    return raw_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fee043",
   "metadata": {},
   "source": [
    "#### Finding .edf files in path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "50119d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_edf(subject):\n",
    "    raw_files = []\n",
    "    for file in os.listdir(os.path.join(edf_path, subject)):\n",
    "        if not file.startswith('.'):\n",
    "            if \".edf\" in file:\n",
    "                raw_files.append(file)\n",
    "    \n",
    "    return raw_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e3bf326d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_annotation(anno_file, raw):\n",
    "    # load mat file with annotation\n",
    "    mat_data = scipy.io.loadmat(anno_file)\n",
    "    states = mat_data[\"states\"]\n",
    "\n",
    "    # get values from 2d array\n",
    "    descriptions = [str(int(s[0])) for s in states]  # state labels as strings\n",
    "    onsets = [float(s[2]) for s in states]           # onset in seconds\n",
    "    durations = [float(s[3]) for s in states]        # duration in seconds\n",
    "\n",
    "    # create annotations object\n",
    "    annotations = mne.Annotations(onset=onsets, duration=durations, description=descriptions)\n",
    "\n",
    "    # set annotations\n",
    "    raw.set_annotations(annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e62f0f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_to_anno(raw):\n",
    "    segments = []\n",
    "    for onset, duration in zip(raw.annotations.onset, raw.annotations.duration):\n",
    "        seg = raw.copy().crop(tmin=onset, tmax=min(onset+duration, raw.times[-1]))  # lazy if preload=False\n",
    "        segments.append(seg)\n",
    "\n",
    "    raw_cropped = mne.concatenate_raws(segments)\n",
    "    \n",
    "    return raw_cropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "62101b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_power_band(raw):\n",
    "    sf = raw.info['sfreq']\n",
    "    results = []\n",
    "    raw_eeg = raw.copy().pick_types(eeg=True)\n",
    "\n",
    "    # Loop over annotations\n",
    "    for annot in raw_eeg.annotations:\n",
    "        stage = annot['description']\n",
    "        onset = annot['onset']\n",
    "        duration = annot['duration']\n",
    "\n",
    "        n_chunks = int(np.ceil(duration / chunk_duration))\n",
    "\n",
    "        for i in range(n_chunks):\n",
    "            tmin = onset + i * chunk_duration\n",
    "            tmax = min(onset + duration, tmin + chunk_duration)\n",
    "\n",
    "            # Crop raw to this chunk\n",
    "            raw_chunk = raw_eeg.copy().crop(tmin=tmin, tmax=min(tmax, raw_eeg.times[-1]))\n",
    "            data = raw_chunk.get_data()           # channels x samples\n",
    "            data = data.astype(float)             # convert to float for YASA\n",
    "            if data.shape[1] < 1000:\n",
    "                continue\n",
    "            print(f\"data shape: {data.shape}\")\n",
    "\n",
    "            # Compute bandpower using YASA (returns DataFrame)\n",
    "            bp_df = yasa.bandpower(data, sf=sf, bands=bands)\n",
    "\n",
    "            # Add the stage column\n",
    "            bp_df['Stage'] = stage\n",
    "\n",
    "            # Add channel names\n",
    "            bp_df['Channel'] = raw_eeg.info['ch_names']\n",
    "\n",
    "            # Append to results\n",
    "            results.append(bp_df)\n",
    "\n",
    "    # Concatenate all chunks\n",
    "    results_df = pd.concat(results, ignore_index=True)\n",
    "\n",
    "    # Optional: average per stage/channel/band\n",
    "    bp_mean = results_df.groupby(['Stage', 'Channel']).mean().reset_index()\n",
    "\n",
    "    return bp_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "15cd82cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def electrode_loc(pos_file):\n",
    "    left_channels, right_channels = [], []\n",
    "    tree = ET.parse(pos_file)\n",
    "    root = tree.getroot()\n",
    "    egi = {'egi': 'http://www.egi.com/sensorLayout_mff'}\n",
    "\n",
    "    for sensor in root.findall('.//egi:sensor', egi):\n",
    "        electrode = sensor.find('egi:number', egi)\n",
    "        x = float(sensor.find('egi:x', egi).text)\n",
    "        if x < 0:\n",
    "            right_channels.append(f\"E{electrode.text.strip()}\")\n",
    "        else:\n",
    "            left_channels.append(f\"E{electrode.text.strip()}\")\n",
    "\n",
    "    return right_channels, left_channels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "4a235e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_channel(target_stage, target_band):\n",
    "    ref_ch = \"\"\n",
    "    # get dataframe with only target stage electrodes\n",
    "    df_stage = bp_mean[bp_mean['Stage'] == target_stage]\n",
    "    # get electrode with highest power\n",
    "    max_row = df_stage.loc[df_stage[target_band].idxmax()]['Channel']\n",
    "    # get the reference electrode\n",
    "    # if max_row in left_channels:\n",
    "    #     ref_ch = \"E190\"\n",
    "    # elif max_row in right_channels:\n",
    "    #     ref_ch = \"E94\"\n",
    "    \n",
    "\n",
    "    # raw_copy = raw_cropped.copy().pick([max_row, ref_ch]\n",
    "    raw_copy = raw_cropped.copy().pick([max_row])\n",
    "    raw_copy.load_data()\n",
    "    # apply filters to channels\n",
    "    raw_copy._data = mne.filter.detrend(raw_copy.get_data(), axis=1, order=1)\n",
    "    raw_copy.filter(l_freq=0.25, h_freq=40, picks='all')\n",
    "    # create bipolar channel\n",
    "    # mne.set_bipolar_reference(\n",
    "    #     raw_copy, \n",
    "    #     anode=max_row, \n",
    "    #     cathode=ref_ch, \n",
    "    #     ch_name=target_band,  \n",
    "    #     copy=False\n",
    "    # )\n",
    "\n",
    "    # ch_data = raw_copy.get_data(target_band)\n",
    "    ch_data = raw_copy.get_data()\n",
    "    \n",
    "    return max_row, ch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a18b3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emg(raw_cropped):\n",
    "    #data = raw_cropped.copy().pick(['E240', 'E243'])\n",
    "    data = raw_cropped.copy().pick(['EMG1', 'EMG2'])\n",
    "    data.load_data()\n",
    "\n",
    "    data._data = mne.filter.detrend(data._data, axis=1, order=1)\n",
    "    #data.filter(l_freq=0.25, h_freq=40, picks=['EMG1', 'EMG2'])\n",
    "    data.filter(l_freq=0.25, h_freq=40)\n",
    "    #picks = mne.pick_channels(data.ch_names, ['E240', 'E243'])\n",
    "    #picks = mne.pick_channels(data.ch_names, ['EMG1', 'EMG2'])\n",
    "    # data_c = data.get_data(picks).copy()\n",
    "    l,r = data\n",
    "    l, r = np.abs(l), np.abs(r)\n",
    "\n",
    "    # # Step 3: envelope via Hilbert\n",
    "    l = np.abs(hilbert(l))\n",
    "    r = np.abs(hilbert(r))\n",
    "\n",
    "    # Step 4: combine (average)\n",
    "    emg_combined = (l + r) / 2\n",
    "\n",
    "    return emg_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476a785d",
   "metadata": {},
   "source": [
    "## Access config parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "a710342c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('extract_egi_config.yaml') as p:\n",
    "    params = yaml.safe_load(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb85ec0a",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "743c8c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wake time (s) to save before first sleep and after last sleep\n",
    "# (30 mins, so 30(s) * 60(s))\n",
    "wake_time = params['variables']['wake_time']\n",
    "# which channels to extract\n",
    "emg_channels = params['variables']['emg_channels']\n",
    "# stage names and corresponding ids\n",
    "bands_list = params['variables']['power_bands']\n",
    "bands = [tuple(band_list) for band_list in bands_list]\n",
    "chunk_duration = params['variables']['chunk_time']\n",
    "\n",
    "# path to general data\n",
    "path_to_data = params['paths']['data']\n",
    "# partial path to raw PSG files\n",
    "path_to_egi = params['paths']['egi']\n",
    "path_to_edf = params['paths']['edf']\n",
    "# partial path to raw hypnogram annotation files\n",
    "path_to_anno_n1 = params['paths']['anno_n1']\n",
    "path_to_anno_n2 = params['paths']['anno_n2']\n",
    "# partial path to the output for the .mat files\n",
    "path_to_output = params['paths']['output']\n",
    "\n",
    "# complete file paths\n",
    "egi_path = os.path.join(path_to_data, path_to_egi)\n",
    "edf_path = os.path.join(path_to_data, path_to_edf)\n",
    "anno_n1_path = os.path.join(path_to_data, path_to_anno_n1)\n",
    "anno_n2_path = os.path.join(path_to_data, path_to_anno_n2)\n",
    "output_path = os.path.join(path_to_data, path_to_output)\n",
    "\n",
    "# regex pattern to extract subject\n",
    "sub_pattern = re.compile(r\"(S\\d{2})\")\n",
    "#night_pattern = re.compile(r\"(S\\d{2}_\\d_\\d)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00a6ea5",
   "metadata": {},
   "source": [
    "## Find all raw and annotations files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "73f372b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "anno_files = []\n",
    "\n",
    "# find all subjects\n",
    "subjects = [\n",
    "    subject for subject in os.listdir(edf_path)\n",
    "    if sub_pattern.search(subject)\n",
    "]\n",
    "# print(f\"Amount of subjects: {len(subjects)}\")\n",
    "\n",
    "# print(f\"Amount of raw files: {len(raw_files)}\")\n",
    "\n",
    "# for anno1, anno2 in zip(os.listdir(anno_n1_path), os.listdir(anno_n2_path)):\n",
    "#     if not anno1.startswith('.') and not anno2.startswith('.'):\n",
    "#         if \".mat\" in anno1 and \".mat\" in anno2:\n",
    "#             anno_files.append(anno1)\n",
    "#             anno_files.append(anno2)\n",
    "\n",
    "# print(f\"Amount of annotation files: {len(anno_files)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42293258",
   "metadata": {},
   "source": [
    "## Create mat files for each subject"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874b4b42",
   "metadata": {},
   "source": [
    "### .RAW files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "efcf2a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for subject in subjects:\n",
    "#     # get the raw files from this current subject\n",
    "#     raw_files = find_raw(subject)\n",
    "\n",
    "#     # iterate nights of subject\n",
    "#     for file in raw_files:\n",
    "#         if \"_1\" in file:\n",
    "#             subject_n = f\"{subject}_1\"\n",
    "#         else:\n",
    "#             subject_n = f\"{subject}_2\"\n",
    "\n",
    "#          # create output directory per subject\n",
    "#         output = os.path.join(output_path, subject_n)\n",
    "#         try:\n",
    "#             os.mkdir(output)\n",
    "#         except OSError as e:\n",
    "#             print(e)\n",
    "#             print(\"Directory already exists.\")\n",
    "#             continue\n",
    "        \n",
    "#         # read raw data\n",
    "#         start = time.time()\n",
    "#         raw = mne.io.read_raw_egi(\n",
    "#             os.path.join(raw_path, subject, file),\n",
    "#             preload=False,\n",
    "#             verbose='error'\n",
    "#         )\n",
    "#         end = time.time()\n",
    "#         print(f\"Reading raw took {end-start:.4f} seconds\")\n",
    "#         directory = file.split(\" \")[0]\n",
    "#         if \"_1\" in file:\n",
    "#             for file in os.listdir(anno_n1_path):\n",
    "#                 if directory in file:\n",
    "#                     anno_file = os.path.join(anno_n1_path, file)\n",
    "#             # extract and annotate raw data\n",
    "#             add_annotation(anno_file, raw)\n",
    "#         else:\n",
    "#             for file in os.listdir(anno_n2_path):\n",
    "#                 if directory in file:\n",
    "#                     anno_file = os.path.join(anno_n2_path, file)\n",
    "#             # extract and annotate raw data\n",
    "#             add_annotation(anno_file, raw)\n",
    "\n",
    "#         for file in os.listdir(os.path.join(raw_path, subject)):\n",
    "#             if not file.startswith(\".\"):\n",
    "#                 dir_path = os.path.join(raw_path, subject, file)\n",
    "#                 if os.path.isdir(dir_path) and directory in file:\n",
    "#                     pos_file = os.path.join(dir_path, \"sensorLayout.xml\")\n",
    "\n",
    "#         # create list to save sleep states to\n",
    "#         sleep_states = []\n",
    "        \n",
    "#         ### Cropping\n",
    "#         ################################################################\n",
    "#         if raw.times[-1] > raw.annotations.duration.sum():\n",
    "#             cropped_to_anno_raw = crop_to_anno(raw)\n",
    "#         #crop the raw data\n",
    "#         raw_cropped = bmf.crop_data(cropped_to_anno_raw, wake_time)\n",
    "#         ################################################################\n",
    "\n",
    "#         ### Sleep states\n",
    "#         ################################################################\n",
    "#         # get sleep states from cropped raw and save to .mat file\n",
    "#         sleep_states = spf.get_stages(raw_cropped, {\"0\":0,\"1\":1,\"2\":2,\"3\":3,\"5\":4})\n",
    "#         spf.create_mat(output, subject_n, \"sleep_states\", sleep_states)\n",
    "#         ################################################################\n",
    "\n",
    "#         # electrode locations\n",
    "#         right_channels, left_channels = electrode_loc(pos_file)\n",
    "\n",
    "#         ### PSD\n",
    "#         ################################################################\n",
    "#         start = time.time()\n",
    "#         print(len(raw_cropped))\n",
    "#         bp_mean = get_power_band(raw_cropped)\n",
    "#         end = time.time()\n",
    "#         print(f\"Computing PSD took {end-start:.4f} seconds\")\n",
    "#         ################################################################\n",
    "\n",
    "#         ### get the best channel for each power band\n",
    "#         # dictionary to save the different bands with highest \n",
    "#         # power in specific channel\n",
    "#         channel_bands = {}\n",
    "\n",
    "#         target_stages = [\"0\", \"3\", \"1\", \"2\", \"0\", \"0\"]\n",
    "#         target_bands = [\"Noise\", \"Delta\", \"Theta\", \"Sigma\", \"Beta\", \"Gamma\"]\n",
    "#         start = time.time()\n",
    "#         results = Parallel(n_jobs=6)(delayed(best_channel)(target_stage, target_band) for target_stage, target_band in zip(target_stages, target_bands))\n",
    "#         print(results)\n",
    "#         end = time.time()\n",
    "#         print(f\"Retrieving best channel took {end-start:.4f} seconds\")\n",
    "#         counter = 0\n",
    "#         for r in results:\n",
    "#             print(r)\n",
    "#             if r[0] not in channel_bands:\n",
    "#                 print(r[0])\n",
    "#                 channel_bands[r[0]] = {}\n",
    "#             channel_bands[r[0]][target_bands[counter]] = r[1] \n",
    "#             counter += 1 \n",
    "\n",
    "#         for channel, bands_d in channel_bands.items():\n",
    "#             band_list = []\n",
    "#             print(channel)\n",
    "#             print(bands_d)\n",
    "#             for band, ch_data in bands_d.items():\n",
    "#                 ch_data = ch_data\n",
    "#                 band_list.append(band)\n",
    "\n",
    "#             ch_pb = [channel] + band_list\n",
    "#             ch_pb = \"_\".join(ch_pb)\n",
    "#             spf.create_mat(output, subject_n, ch_pb, ch_data)\n",
    "\n",
    "#         emg_combined = get_emg(raw_cropped)\n",
    "#         spf.create_mat(output, subject_n, \"EMG\", emg_combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0e2c11",
   "metadata": {},
   "source": [
    "### .edf files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "ea280a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOTORWP4_S35_1.edf\n",
      "Extracting EDF parameters from C:\\Users\\andri\\school\\bio-informatics\\internship\\donders\\data\\human_test_data\\new_dataset\\EGI\\S35\\MOTORWP4_S35_1.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading raw took 0.3478 seconds\n",
      "MOTORWP4_S35_1\n",
      "MOTORWP4_S35_1 20201211 2224_states.mat\n",
      "C:\\Users\\andri\\school\\bio-informatics\\internship\\donders\\data\\human_test_data\\new_dataset\\HPN\\hpn_files_n1\\MOTORWP4_S35_1 20201211 2224_states.mat\n",
      "MOTORWP4_S36_1 20210125 22_states.mat\n",
      "First sleep starts at: 0.0\n",
      "Last sleep ends at: 29160.372\n",
      "Cropping raw: 0 - 29160.372\n",
      "Cropping finished.\n",
      "Sleep stages variable can't be reshaped.\n",
      "Saving the sleep stages to .mat file.\n",
      "7290094\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 22501)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 7501)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 60001)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 67501)\n",
      "data shape: (10, 30001)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 15001)\n",
      "data shape: (10, 7501)\n",
      "data shape: (10, 30001)\n",
      "data shape: (10, 15001)\n",
      "data shape: (10, 60001)\n",
      "data shape: (10, 67501)\n",
      "data shape: (10, 7501)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 67501)\n",
      "data shape: (10, 15001)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 52501)\n",
      "data shape: (10, 7501)\n",
      "data shape: (10, 7501)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 37501)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 7501)\n",
      "data shape: (10, 7501)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 7501)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 15001)\n",
      "data shape: (10, 7501)\n",
      "data shape: (10, 52501)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 22501)\n",
      "data shape: (10, 7501)\n",
      "data shape: (10, 37501)\n",
      "data shape: (10, 7501)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 60001)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 15001)\n",
      "data shape: (10, 7501)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 37501)\n",
      "data shape: (10, 37501)\n",
      "data shape: (10, 67501)\n",
      "data shape: (10, 7501)\n",
      "data shape: (10, 15001)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 30001)\n",
      "data shape: (10, 37501)\n",
      "data shape: (10, 7501)\n",
      "data shape: (10, 7501)\n",
      "data shape: (10, 15001)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 37501)\n",
      "data shape: (10, 7501)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 52501)\n",
      "data shape: (10, 15001)\n",
      "data shape: (10, 7501)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 30001)\n",
      "data shape: (10, 7501)\n",
      "data shape: (10, 7501)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 15001)\n",
      "data shape: (10, 15001)\n",
      "data shape: (10, 22501)\n",
      "data shape: (10, 7501)\n",
      "data shape: (10, 7501)\n",
      "data shape: (10, 52501)\n",
      "data shape: (10, 7501)\n",
      "data shape: (10, 7501)\n",
      "data shape: (10, 7501)\n",
      "data shape: (10, 22501)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 30001)\n",
      "data shape: (10, 22501)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 30001)\n",
      "data shape: (10, 7501)\n",
      "data shape: (10, 7501)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 30001)\n",
      "data shape: (10, 7501)\n",
      "data shape: (10, 15001)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 30001)\n",
      "data shape: (10, 7501)\n",
      "data shape: (10, 45001)\n",
      "data shape: (10, 7501)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 52501)\n",
      "data shape: (10, 22501)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 7501)\n",
      "data shape: (10, 22501)\n",
      "data shape: (10, 15001)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 22501)\n",
      "data shape: (10, 52501)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 52501)\n",
      "data shape: (10, 67501)\n",
      "data shape: (10, 15001)\n",
      "data shape: (10, 22501)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 45001)\n",
      "data shape: (10, 15001)\n",
      "data shape: (10, 15001)\n",
      "data shape: (10, 37501)\n",
      "data shape: (10, 15001)\n",
      "data shape: (10, 22501)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 7501)\n",
      "data shape: (10, 7501)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 7501)\n",
      "data shape: (10, 75001)\n",
      "Computing PSD took 20.2937 seconds\n",
      "[('EOG2', array([[-1.69406589e-20, -2.42504889e-06, -4.88595654e-06, ...,\n",
      "        -3.07965361e-06, -3.59494732e-06,  0.00000000e+00]],\n",
      "      shape=(1, 7290094))), ('F1', array([[-6.77626358e-21,  2.22727069e-05,  3.10481985e-05, ...,\n",
      "         2.22336831e-06,  1.70763329e-06, -6.77626358e-21]],\n",
      "      shape=(1, 7290094))), ('C1', array([[-2.87991202e-20,  2.16083408e-05,  2.90933813e-05, ...,\n",
      "         4.66514386e-06,  3.01296429e-06,  0.00000000e+00]],\n",
      "      shape=(1, 7290094))), ('F1', array([[-6.77626358e-21,  2.22727069e-05,  3.10481985e-05, ...,\n",
      "         2.22336831e-06,  1.70763329e-06, -6.77626358e-21]],\n",
      "      shape=(1, 7290094))), ('F2', array([[-2.87991202e-20,  4.47033406e-06,  4.78572623e-06, ...,\n",
      "         8.47352853e-06,  8.28913571e-06, -6.77626358e-21]],\n",
      "      shape=(1, 7290094))), ('F2', array([[-2.87991202e-20,  4.47033406e-06,  4.78572623e-06, ...,\n",
      "         8.47352853e-06,  8.28913571e-06, -6.77626358e-21]],\n",
      "      shape=(1, 7290094)))]\n",
      "Retrieving best channel took 11.4341 seconds\n",
      "('EOG2', array([[-1.69406589e-20, -2.42504889e-06, -4.88595654e-06, ...,\n",
      "        -3.07965361e-06, -3.59494732e-06,  0.00000000e+00]],\n",
      "      shape=(1, 7290094)))\n",
      "EOG2\n",
      "('F1', array([[-6.77626358e-21,  2.22727069e-05,  3.10481985e-05, ...,\n",
      "         2.22336831e-06,  1.70763329e-06, -6.77626358e-21]],\n",
      "      shape=(1, 7290094)))\n",
      "F1\n",
      "('C1', array([[-2.87991202e-20,  2.16083408e-05,  2.90933813e-05, ...,\n",
      "         4.66514386e-06,  3.01296429e-06,  0.00000000e+00]],\n",
      "      shape=(1, 7290094)))\n",
      "C1\n",
      "('F1', array([[-6.77626358e-21,  2.22727069e-05,  3.10481985e-05, ...,\n",
      "         2.22336831e-06,  1.70763329e-06, -6.77626358e-21]],\n",
      "      shape=(1, 7290094)))\n",
      "('F2', array([[-2.87991202e-20,  4.47033406e-06,  4.78572623e-06, ...,\n",
      "         8.47352853e-06,  8.28913571e-06, -6.77626358e-21]],\n",
      "      shape=(1, 7290094)))\n",
      "F2\n",
      "('F2', array([[-2.87991202e-20,  4.47033406e-06,  4.78572623e-06, ...,\n",
      "         8.47352853e-06,  8.28913571e-06, -6.77626358e-21]],\n",
      "      shape=(1, 7290094)))\n",
      "EOG2\n",
      "{'Noise': array([[-1.69406589e-20, -2.42504889e-06, -4.88595654e-06, ...,\n",
      "        -3.07965361e-06, -3.59494732e-06,  0.00000000e+00]],\n",
      "      shape=(1, 7290094))}\n",
      "F1\n",
      "{'Delta': array([[-6.77626358e-21,  2.22727069e-05,  3.10481985e-05, ...,\n",
      "         2.22336831e-06,  1.70763329e-06, -6.77626358e-21]],\n",
      "      shape=(1, 7290094)), 'Sigma': array([[-6.77626358e-21,  2.22727069e-05,  3.10481985e-05, ...,\n",
      "         2.22336831e-06,  1.70763329e-06, -6.77626358e-21]],\n",
      "      shape=(1, 7290094))}\n",
      "C1\n",
      "{'Theta': array([[-2.87991202e-20,  2.16083408e-05,  2.90933813e-05, ...,\n",
      "         4.66514386e-06,  3.01296429e-06,  0.00000000e+00]],\n",
      "      shape=(1, 7290094))}\n",
      "F2\n",
      "{'Beta': array([[-2.87991202e-20,  4.47033406e-06,  4.78572623e-06, ...,\n",
      "         8.47352853e-06,  8.28913571e-06, -6.77626358e-21]],\n",
      "      shape=(1, 7290094)), 'Gamma': array([[-2.87991202e-20,  4.47033406e-06,  4.78572623e-06, ...,\n",
      "         8.47352853e-06,  8.28913571e-06, -6.77626358e-21]],\n",
      "      shape=(1, 7290094))}\n",
      "Reading 0 ... 7290093  =      0.000 ... 29160.372 secs...\n",
      "Filtering raw data in 94 contiguous segments\n",
      "Setting up band-pass filter from 0.25 - 40 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.25\n",
      "- Lower transition bandwidth: 0.25 Hz (-6 dB cutoff frequency: 0.12 Hz)\n",
      "- Upper passband edge: 40.00 Hz\n",
      "- Upper transition bandwidth: 10.00 Hz (-6 dB cutoff frequency: 45.00 Hz)\n",
      "- Filter length: 3301 samples (13.204 s)\n",
      "\n",
      "MOTORWP4_S35_2.edf\n",
      "Extracting EDF parameters from C:\\Users\\andri\\school\\bio-informatics\\internship\\donders\\data\\human_test_data\\new_dataset\\EGI\\S35\\MOTORWP4_S35_2.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading raw took 0.2706 seconds\n",
      "MOTORWP4_S35_2\n",
      "First sleep starts at: 0.0\n",
      "Last sleep ends at: 27690.312\n",
      "Cropping raw: 0 - 27690.312\n",
      "Cropping finished.\n",
      "Sleep stages variable can't be reshaped.\n",
      "Saving the sleep stages to .mat file.\n",
      "6922579\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 37501)\n",
      "data shape: (10, 22501)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 52501)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 45001)\n",
      "data shape: (10, 7501)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 22501)\n",
      "data shape: (10, 7501)\n",
      "data shape: (10, 15001)\n",
      "data shape: (10, 7501)\n",
      "data shape: (10, 37501)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 15001)\n",
      "data shape: (10, 15001)\n",
      "data shape: (10, 7501)\n",
      "data shape: (10, 30001)\n",
      "data shape: (10, 7501)\n",
      "data shape: (10, 52501)\n",
      "data shape: (10, 7501)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 15001)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 22501)\n",
      "data shape: (10, 7501)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 22501)\n",
      "data shape: (10, 52501)\n",
      "data shape: (10, 22501)\n",
      "data shape: (10, 60001)\n",
      "data shape: (10, 15001)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 22501)\n",
      "data shape: (10, 7501)\n",
      "data shape: (10, 7501)\n",
      "data shape: (10, 37501)\n",
      "data shape: (10, 7501)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 30001)\n",
      "data shape: (10, 7501)\n",
      "data shape: (10, 7501)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 7501)\n",
      "data shape: (10, 7501)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 52501)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 37501)\n",
      "data shape: (10, 7501)\n",
      "data shape: (10, 67501)\n",
      "data shape: (10, 7501)\n",
      "data shape: (10, 22501)\n",
      "data shape: (10, 7501)\n",
      "data shape: (10, 7501)\n",
      "data shape: (10, 60001)\n",
      "data shape: (10, 15001)\n",
      "data shape: (10, 37501)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 7501)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 52501)\n",
      "data shape: (10, 15001)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 7501)\n",
      "data shape: (10, 7501)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 60001)\n",
      "data shape: (10, 7501)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 37501)\n",
      "data shape: (10, 15001)\n",
      "data shape: (10, 15001)\n",
      "data shape: (10, 7501)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 52501)\n",
      "data shape: (10, 7501)\n",
      "data shape: (10, 7501)\n",
      "data shape: (10, 45001)\n",
      "data shape: (10, 7501)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 7501)\n",
      "data shape: (10, 7501)\n",
      "data shape: (10, 22501)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 45001)\n",
      "data shape: (10, 7501)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 60001)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 52501)\n",
      "data shape: (10, 7501)\n",
      "data shape: (10, 7501)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 67501)\n",
      "data shape: (10, 7501)\n",
      "data shape: (10, 15001)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 60001)\n",
      "data shape: (10, 75001)\n",
      "data shape: (10, 30001)\n",
      "Computing PSD took 21.9935 seconds\n",
      "[('EOG1', array([[ 0.00000000e+00, -2.93821899e-07, -2.42449144e-08, ...,\n",
      "         1.30240712e-05,  6.63733055e-06,  9.48676901e-20]],\n",
      "      shape=(1, 6922579))), ('F1', array([[ 0.00000000e+00, -3.49882767e-07, -7.07863920e-07, ...,\n",
      "         9.71219363e-06,  5.08194223e-06,  1.23327997e-18]],\n",
      "      shape=(1, 6922579))), ('EMG1', array([[-2.71050543e-20,  1.14409349e-05,  1.90772666e-05, ...,\n",
      "        -8.32940265e-07, -4.55459450e-07,  8.19927893e-19]],\n",
      "      shape=(1, 6922579))), ('C2', array([[ 0.00000000e+00, -9.02827689e-06, -1.43247567e-05, ...,\n",
      "         1.90575689e-05,  9.71469788e-06,  2.84603070e-19]],\n",
      "      shape=(1, 6922579))), ('F2', array([[ 1.35525272e-20, -9.24008667e-06, -1.43547306e-05, ...,\n",
      "         5.96442958e-04,  3.08833002e-04,  2.57498016e-19]],\n",
      "      shape=(1, 6922579))), ('C2', array([[ 0.00000000e+00, -9.02827689e-06, -1.43247567e-05, ...,\n",
      "         1.90575689e-05,  9.71469788e-06,  2.84603070e-19]],\n",
      "      shape=(1, 6922579)))]\n",
      "Retrieving best channel took 5.1129 seconds\n",
      "('EOG1', array([[ 0.00000000e+00, -2.93821899e-07, -2.42449144e-08, ...,\n",
      "         1.30240712e-05,  6.63733055e-06,  9.48676901e-20]],\n",
      "      shape=(1, 6922579)))\n",
      "EOG1\n",
      "('F1', array([[ 0.00000000e+00, -3.49882767e-07, -7.07863920e-07, ...,\n",
      "         9.71219363e-06,  5.08194223e-06,  1.23327997e-18]],\n",
      "      shape=(1, 6922579)))\n",
      "F1\n",
      "('EMG1', array([[-2.71050543e-20,  1.14409349e-05,  1.90772666e-05, ...,\n",
      "        -8.32940265e-07, -4.55459450e-07,  8.19927893e-19]],\n",
      "      shape=(1, 6922579)))\n",
      "EMG1\n",
      "('C2', array([[ 0.00000000e+00, -9.02827689e-06, -1.43247567e-05, ...,\n",
      "         1.90575689e-05,  9.71469788e-06,  2.84603070e-19]],\n",
      "      shape=(1, 6922579)))\n",
      "C2\n",
      "('F2', array([[ 1.35525272e-20, -9.24008667e-06, -1.43547306e-05, ...,\n",
      "         5.96442958e-04,  3.08833002e-04,  2.57498016e-19]],\n",
      "      shape=(1, 6922579)))\n",
      "F2\n",
      "('C2', array([[ 0.00000000e+00, -9.02827689e-06, -1.43247567e-05, ...,\n",
      "         1.90575689e-05,  9.71469788e-06,  2.84603070e-19]],\n",
      "      shape=(1, 6922579)))\n",
      "EOG1\n",
      "{'Noise': array([[ 0.00000000e+00, -2.93821899e-07, -2.42449144e-08, ...,\n",
      "         1.30240712e-05,  6.63733055e-06,  9.48676901e-20]],\n",
      "      shape=(1, 6922579))}\n",
      "F1\n",
      "{'Delta': array([[ 0.00000000e+00, -3.49882767e-07, -7.07863920e-07, ...,\n",
      "         9.71219363e-06,  5.08194223e-06,  1.23327997e-18]],\n",
      "      shape=(1, 6922579))}\n",
      "EMG1\n",
      "{'Theta': array([[-2.71050543e-20,  1.14409349e-05,  1.90772666e-05, ...,\n",
      "        -8.32940265e-07, -4.55459450e-07,  8.19927893e-19]],\n",
      "      shape=(1, 6922579))}\n",
      "C2\n",
      "{'Sigma': array([[ 0.00000000e+00, -9.02827689e-06, -1.43247567e-05, ...,\n",
      "         1.90575689e-05,  9.71469788e-06,  2.84603070e-19]],\n",
      "      shape=(1, 6922579)), 'Gamma': array([[ 0.00000000e+00, -9.02827689e-06, -1.43247567e-05, ...,\n",
      "         1.90575689e-05,  9.71469788e-06,  2.84603070e-19]],\n",
      "      shape=(1, 6922579))}\n",
      "F2\n",
      "{'Beta': array([[ 1.35525272e-20, -9.24008667e-06, -1.43547306e-05, ...,\n",
      "         5.96442958e-04,  3.08833002e-04,  2.57498016e-19]],\n",
      "      shape=(1, 6922579))}\n",
      "Reading 0 ... 6922578  =      0.000 ... 27690.312 secs...\n",
      "Filtering raw data in 79 contiguous segments\n",
      "Setting up band-pass filter from 0.25 - 40 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.25\n",
      "- Lower transition bandwidth: 0.25 Hz (-6 dB cutoff frequency: 0.12 Hz)\n",
      "- Upper passband edge: 40.00 Hz\n",
      "- Upper transition bandwidth: 10.00 Hz (-6 dB cutoff frequency: 45.00 Hz)\n",
      "- Filter length: 3301 samples (13.204 s)\n",
      "\n",
      "MOTORWP4_S36_1.edf\n",
      "[WinError 183] Cannot create a file when that file already exists: 'C:\\\\Users\\\\andri\\\\school\\\\bio-informatics\\\\internship\\\\donders\\\\data\\\\human_test_data\\\\pre_processing\\\\mat_files\\\\S36_1_edf'\n",
      "Directory already exists.\n",
      "MOTORWP4_S36_2.edf\n",
      "[WinError 183] Cannot create a file when that file already exists: 'C:\\\\Users\\\\andri\\\\school\\\\bio-informatics\\\\internship\\\\donders\\\\data\\\\human_test_data\\\\pre_processing\\\\mat_files\\\\S36_2_edf'\n",
      "Directory already exists.\n"
     ]
    }
   ],
   "source": [
    "for subject in subjects:\n",
    "    # get the raw files from this current subject\n",
    "    raw_files = find_edf(subject)\n",
    "\n",
    "    # iterate nights of subject\n",
    "    for file in raw_files:\n",
    "        print(file)\n",
    "        if \"_1\" in file:\n",
    "            subject_n = f\"{subject}_1_edf\"\n",
    "        else:\n",
    "            subject_n = f\"{subject}_2_edf\"\n",
    "\n",
    "         # create output directory per subject\n",
    "        output = os.path.join(output_path, subject_n)\n",
    "        try:\n",
    "            os.mkdir(output)\n",
    "        except OSError as e:\n",
    "            print(e)\n",
    "            print(\"Directory already exists.\")\n",
    "            continue\n",
    "        \n",
    "        # read raw data\n",
    "        start = time.time()\n",
    "        raw = mne.io.read_raw_edf(os.path.join(edf_path, subject, file))\n",
    "        end = time.time()\n",
    "        print(f\"Reading raw took {end-start:.4f} seconds\")\n",
    "        directory = file.split(\".\")[0]\n",
    "        print(directory)\n",
    "        if \"_1\" in file:\n",
    "            for file in os.listdir(anno_n1_path):\n",
    "                print(file)\n",
    "                if directory in file:\n",
    "                    anno_file1 = os.path.join(anno_n1_path, file)\n",
    "                    print(anno_file1)\n",
    "            # extract and annotate raw data\n",
    "            add_annotation(anno_file1, raw)\n",
    "        else:\n",
    "            for file in os.listdir(anno_n2_path):\n",
    "                if directory in file:\n",
    "                    anno_file2 = os.path.join(anno_n2_path, file)\n",
    "            # extract and annotate raw data\n",
    "            add_annotation(anno_file2, raw)\n",
    "\n",
    "        for file in os.listdir(os.path.join(edf_path, subject)):\n",
    "            if not file.startswith(\".\"):\n",
    "                dir_path = os.path.join(edf_path, subject, file)\n",
    "                if os.path.isdir(dir_path) and directory in file:\n",
    "                    pos_file = os.path.join(dir_path, \"sensorLayout.xml\")\n",
    "\n",
    "        # create list to save sleep states to\n",
    "        sleep_states = []\n",
    "        \n",
    "        ### Cropping\n",
    "        ################################################################\n",
    "        if raw.times[-1] > raw.annotations.duration.sum():\n",
    "            cropped_to_anno_raw = crop_to_anno(raw)\n",
    "        #crop the raw data\n",
    "        raw_cropped = bmf.crop_data(cropped_to_anno_raw, wake_time)\n",
    "        ################################################################\n",
    "\n",
    "        ### Sleep states\n",
    "        ################################################################\n",
    "        # get sleep states from cropped raw and save to .mat file\n",
    "        sleep_states = spf.get_stages(raw_cropped, {\"0\":0,\"1\":1,\"2\":2,\"3\":3,\"5\":4})\n",
    "        spf.create_mat(output, subject_n, \"sleep_states\", sleep_states)\n",
    "        ################################################################\n",
    "\n",
    "        # electrode locations\n",
    "        right_channels, left_channels = electrode_loc(pos_file)\n",
    "\n",
    "        ### PSD\n",
    "        ################################################################\n",
    "        start = time.time()\n",
    "        print(len(raw_cropped))\n",
    "        bp_mean = get_power_band(raw_cropped)\n",
    "        end = time.time()\n",
    "        print(f\"Computing PSD took {end-start:.4f} seconds\")\n",
    "        ################################################################\n",
    "\n",
    "        ### get the best channel for each power band\n",
    "        # dictionary to save the different bands with highest \n",
    "        # power in specific channel\n",
    "        channel_bands = {}\n",
    "\n",
    "        target_stages = [\"0\", \"3\", \"1\", \"2\", \"0\", \"0\"]\n",
    "        target_bands = [\"Noise\", \"Delta\", \"Theta\", \"Sigma\", \"Beta\", \"Gamma\"]\n",
    "        start = time.time()\n",
    "        results = Parallel(n_jobs=6)(delayed(best_channel)(target_stage, target_band) for target_stage, target_band in zip(target_stages, target_bands))\n",
    "        print(results)\n",
    "        end = time.time()\n",
    "        print(f\"Retrieving best channel took {end-start:.4f} seconds\")\n",
    "        counter = 0\n",
    "        for r in results:\n",
    "            print(r)\n",
    "            if r[0] not in channel_bands:\n",
    "                print(r[0])\n",
    "                channel_bands[r[0]] = {}\n",
    "            channel_bands[r[0]][target_bands[counter]] = r[1] \n",
    "            counter += 1 \n",
    "\n",
    "        for channel, bands_d in channel_bands.items():\n",
    "            band_list = []\n",
    "            print(channel)\n",
    "            print(bands_d)\n",
    "            for band, ch_data in bands_d.items():\n",
    "                ch_data = ch_data\n",
    "                band_list.append(band)\n",
    "\n",
    "            ch_pb = [channel] + band_list\n",
    "            ch_pb = \"_\".join(ch_pb)\n",
    "            spf.create_mat(output, subject_n, ch_pb, ch_data)\n",
    "\n",
    "        emg_combined = get_emg(raw_cropped)\n",
    "        spf.create_mat(output, subject_n, \"EMG\", emg_combined)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rodent_model",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
